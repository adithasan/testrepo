/*
Automated Content Moderation:
Auto-Negative-Note-Scan:    The server will need to scan the note’s contents to compare 
                            and decide whether it is appropriate enough to store and 
                            display to other users

Auto-Negative-Note-Inform:  The server should inform the client if the content was deemed 
                            inappropriate

Auto-Negative-Note-Show:    The client should inform the user that their note was not uploaded 
                            due to the note’s content containing inappropriate content
*/

digraph
{
    fontsize = 18
    fontname = Arial
    labelloc = "t"
    labeljust = "l"
    rankdir="TB"

    // System feature title
    label = <<b>Automated Content Moderation</b> - functional requirements are highlighted in red.<br/><br/>>

    overlap="compress"
    node [shape=record fontname=Arial fontsize=12 fillcolor="lightblue"] "AutomatedContentModeration";  // System Reqs
    node [style=filled fillcolor="#FFCCCC"]
    "Auto-Negative-Note-Scan" 
    "Auto-Negative-Note-Inform" 
    "Auto-Negative-Note-Show";                              
    "AutomatedContentModeration" -> "Auto-Negative-Note-Scan";
    "AutomatedContentModeration" -> "Auto-Negative-Note-Inform";
    "AutomatedContentModeration" -> "Auto-Negative-Note-Show";
    node [fillcolor="#FFFFFF"]
    "Auto-Negative-Note-Scan" -> "Implement Text-Analytics service to scan for bad sentiment"
    "Auto-Negative-Note-Scan" -> "Implement Auto-Content-Moderation Service to scan for PIIs"
    "Auto-Negative-Note-Inform" -> "Create an Interceptor using Text-Analytics service"
    "Auto-Negative-Note-Inform" -> "Create an Interceptor using Auto-Content-Moderation"
    "Auto-Negative-Note-Show" -> "Show dialog when server returns DetectedPII error response"
    "Auto-Negative-Note-Show" -> "Show dialog when server returns DetectedBadSentiment error response"
}
